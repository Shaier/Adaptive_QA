{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code to create HotpotQA_cite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "with open('datasets/hotpot_train_v1.1.json') as f:\n",
    "    hotpotqa_train = json.load(f)\n",
    "\n",
    "# val\n",
    "with open('datasets/hotpot_dev_distractor_v1.json') as f: # note that I'll need to split this in 2: val and test\n",
    "    hotpotqa_val = json.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train_questions = []\n",
    "train_original_contexts = []\n",
    "train_original_answers = []\n",
    "train_cited_original_answers = []\n",
    "train_title_to_contexts = []\n",
    "train_cited_oracle_contexts = []\n",
    "train_number_of_documents_list = []\n",
    "train_distractor_contexts = []\n",
    "\n",
    "for entry_idx in range(len(hotpotqa_train)):\n",
    "    # extract\n",
    "    question = hotpotqa_train[entry_idx]['question']\n",
    "    original_answer = hotpotqa_train[entry_idx]['answer']\n",
    "\n",
    "    context = hotpotqa_train[entry_idx]['context']\n",
    "    title_to_citation_dict = {}\n",
    "    title_to_context = {}\n",
    "    full_cited_context = \"\"\n",
    "    for idx, sentences_list in enumerate(context):\n",
    "        doc_id = f'Document {idx+1}'\n",
    "        document_title = sentences_list[0]\n",
    "        paragraph_text = ' '.join(sentences_list[1])\n",
    "        title_to_citation_dict[document_title] = doc_id\n",
    "        title_to_context[document_title] = paragraph_text\n",
    "        cited_sentences = f'{doc_id}: {paragraph_text}'\n",
    "        full_cited_context += f'{cited_sentences} '\n",
    "    \n",
    "    titles = [i[0] for i in hotpotqa_train[entry_idx]['context']]\n",
    "    relevant_titles = list(set([i[0] for i in hotpotqa_train[entry_idx]['supporting_facts']]))\n",
    "    irrelevant_titles = [i for i in titles if i not in relevant_titles]\n",
    "    relevant_citations = [title_to_citation_dict[title] for title in relevant_titles]\n",
    "    irrelevant_citations = [title_to_citation_dict[title] for title in irrelevant_titles]\n",
    "    relevant_context = \" \".join([title_to_context[relevant_title] for relevant_title in relevant_titles])\n",
    "    irrelevant_context = \" \".join([title_to_context[irrelevant_title] for irrelevant_title in irrelevant_titles])\n",
    "    relevant_cited_context = \" \".join([f'{title_to_citation_dict[relevant_title]}: {title_to_context[relevant_title]}' for relevant_title in relevant_titles])\n",
    "    irrelevant_cited_context = \" \".join([f'{title_to_citation_dict[irrelevant_title]}: {title_to_context[irrelevant_title]}' for irrelevant_title in irrelevant_titles])\n",
    "\n",
    "    original_context = full_cited_context\n",
    "    for i in relevant_cited_context.split('. '):\n",
    "        original_context = original_context.replace(i, '')\n",
    "\n",
    "    cited_original_answer = f'According to Documents {sorted(relevant_citations)} the answer is {original_answer}'\n",
    "    number_of_documents = len(hotpotqa_train[entry_idx]['context'])\n",
    "    # append\n",
    "    train_questions.append(question)\n",
    "    train_original_contexts.append(full_cited_context)\n",
    "    train_original_answers.append(original_answer)\n",
    "    train_cited_original_answers.append(cited_original_answer)\n",
    "    train_title_to_contexts.append(title_to_context)\n",
    "    train_cited_oracle_contexts.append(relevant_cited_context)\n",
    "    train_number_of_documents_list.append(number_of_documents)\n",
    "    train_distractor_contexts.append(irrelevant_cited_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val\n",
    "val_questions = []\n",
    "val_original_contexts = []\n",
    "val_original_answers = []\n",
    "val_cited_original_answers = []\n",
    "val_title_to_contexts = []\n",
    "val_cited_oracle_contexts = []\n",
    "val_number_of_documents_list = []\n",
    "val_distractor_contexts = []\n",
    "\n",
    "for entry_idx in range(len(hotpotqa_val)):\n",
    "    # extract\n",
    "    question = hotpotqa_val[entry_idx]['question']\n",
    "    original_answer = hotpotqa_val[entry_idx]['answer']\n",
    "\n",
    "    context = hotpotqa_val[entry_idx]['context']\n",
    "    title_to_citation_dict = {}\n",
    "    title_to_context = {}\n",
    "    full_cited_context = \"\"\n",
    "    for idx, sentences_list in enumerate(context):\n",
    "        doc_id = f'Document {idx+1}'\n",
    "        document_title = sentences_list[0]\n",
    "        paragraph_text = ' '.join(sentences_list[1])\n",
    "        title_to_citation_dict[document_title] = doc_id\n",
    "        title_to_context[document_title] = paragraph_text\n",
    "        cited_sentences = f'{doc_id}: {paragraph_text}'\n",
    "        full_cited_context += f'{cited_sentences} '\n",
    "    \n",
    "    titles = [i[0] for i in hotpotqa_val[entry_idx]['context']]\n",
    "    relevant_titles = list(set([i[0] for i in hotpotqa_val[entry_idx]['supporting_facts']]))\n",
    "    irrelevant_titles = [i for i in titles if i not in relevant_titles]\n",
    "    relevant_citations = [title_to_citation_dict[title] for title in relevant_titles]\n",
    "    irrelevant_citations = [title_to_citation_dict[title] for title in irrelevant_titles]\n",
    "    relevant_context = \" \".join([title_to_context[relevant_title] for relevant_title in relevant_titles])\n",
    "    irrelevant_context = \" \".join([title_to_context[irrelevant_title] for irrelevant_title in irrelevant_titles])\n",
    "    relevant_cited_context = \" \".join([f'{title_to_citation_dict[relevant_title]}: {title_to_context[relevant_title]}' for relevant_title in relevant_titles])\n",
    "    irrelevant_cited_context = \" \".join([f'{title_to_citation_dict[irrelevant_title]}: {title_to_context[irrelevant_title]}' for irrelevant_title in irrelevant_titles])\n",
    "\n",
    "    original_context = full_cited_context\n",
    "    for i in relevant_cited_context.split('. '):\n",
    "        original_context = original_context.replace(i, '')\n",
    "\n",
    "    cited_original_answer = f'According to Documents {sorted(relevant_citations)} the answer is {original_answer}'\n",
    "    number_of_documents = len(hotpotqa_val[entry_idx]['context'])\n",
    "    # append\n",
    "    val_questions.append(question)\n",
    "    val_original_contexts.append(full_cited_context)\n",
    "    val_original_answers.append(original_answer)\n",
    "    val_cited_original_answers.append(cited_original_answer)\n",
    "    val_title_to_contexts.append(title_to_context)\n",
    "    val_cited_oracle_contexts.append(relevant_cited_context)\n",
    "    val_number_of_documents_list.append(number_of_documents)\n",
    "    val_distractor_contexts.append(irrelevant_cited_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame({\n",
    "    'questions' : train_questions,\n",
    "    'original_contexts' : train_original_contexts,\n",
    "    'original_answers' : train_original_answers,\n",
    "    'cited_original_answers' : train_cited_original_answers,\n",
    "    'title_to_contexts' : train_title_to_contexts,\n",
    "    'cited_oracle_contexts' : train_cited_oracle_contexts,\n",
    "    'number_of_documents_list' : train_number_of_documents_list,\n",
    "    'distractor_contexts': train_distractor_contexts,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.DataFrame({\n",
    "    'questions' : val_questions,\n",
    "    'original_contexts' : val_original_contexts,\n",
    "    'original_answers' : val_original_answers,\n",
    "    'cited_original_answers' : val_cited_original_answers,\n",
    "    'title_to_contexts' : val_title_to_contexts,\n",
    "    'cited_oracle_contexts' : val_cited_oracle_contexts,\n",
    "    'number_of_documents_list' : val_number_of_documents_list,\n",
    "    'distractor_contexts': val_distractor_contexts,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create conflicting information using MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create conflicting answers use RoBERTa (distilroberta-base)\n",
    "classifier = pipeline(\"fill-mask\", top_k=5, device=device) # up to 5 conflicting strings (some may be existing answers and then removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train_conflicting_contexts_1 = []\n",
    "train_conflicting_answers_1 = []\n",
    "train_conflicting_contexts_2 = []\n",
    "train_conflicting_answers_2 = []\n",
    "train_cited_conflicting_answers_1 = []\n",
    "train_cited_conflicting_answers_2 = []\n",
    "\n",
    "for entry_idx in range(len(train_original_contexts)):\n",
    "    if entry_idx % 100 == 0:\n",
    "        print(f'entry_idx: {entry_idx} out of {len(train_original_contexts)}')\n",
    "    try:\n",
    "        original_answer = train_original_answers[entry_idx]\n",
    "        original_context = train_cited_oracle_contexts[entry_idx]\n",
    "        if original_answer in original_context:\n",
    "            question = train_questions[entry_idx]\n",
    "            # mask\n",
    "            masked_context = original_context.replace(original_answer, '<mask>', 1) # only replace the first occurence because the fill-mask pipeline can only handle 1 mask at a time (it can do more but then the results look different)\n",
    "            # predict\n",
    "            fill_mask_result = classifier(masked_context) # Note that token_str may contain spaces\n",
    "            # extract\n",
    "            fill_mask_sequences = [i['sequence'] for i in fill_mask_result]\n",
    "            fill_mask_answers = [i['token_str'].strip() for i in fill_mask_result] # remove extra spaces from the pipelines potential result\n",
    "            try:\n",
    "                fill_mask_answers.remove(original_answer) # filter -- remove answers if its the original and append the remaining context and answers\n",
    "            except ValueError: pass # not in list\n",
    "            for idx in range(2): # only append the first 2 answers for 2 conflicting contexts\n",
    "                if idx == 0:\n",
    "                    train_conflicting_contexts_1.append(original_context.replace(original_answer, fill_mask_answers[idx]).replace('  ', ' ')) # and remove extra spaces from the pipeline's potential result)\n",
    "                    train_conflicting_answers_1.append(fill_mask_answers[idx])\n",
    "                    train_cited_conflicting_answers_1.append(train_cited_original_answers[entry_idx].replace(original_answer, fill_mask_answers[idx]).replace('  ', ' '))\n",
    "                if idx == 1:\n",
    "                    train_conflicting_contexts_2.append(original_context.replace(original_answer, fill_mask_answers[idx]).replace('  ', ' ')) # and remove extra spaces from the pipeline's potential result)\n",
    "                    train_conflicting_answers_2.append(fill_mask_answers[idx])\n",
    "                    train_cited_conflicting_answers_2.append(train_cited_original_answers[entry_idx].replace(original_answer, fill_mask_answers[idx]).replace('  ', ' '))\n",
    "\n",
    "            # break\n",
    "        else: # answer does not appear in the context (still need to append something)\n",
    "            train_conflicting_contexts_1.append('NA')\n",
    "            train_conflicting_answers_1.append('NA')\n",
    "            train_conflicting_contexts_2.append('NA')\n",
    "            train_conflicting_answers_2.append('NA')\n",
    "            train_cited_conflicting_answers_1.append('NA')\n",
    "            train_cited_conflicting_answers_2.append('NA')\n",
    "    except (RuntimeError, IndexError) as e: # context is too long\n",
    "        train_conflicting_contexts_1.append('NA')\n",
    "        train_conflicting_answers_1.append('NA')\n",
    "        train_conflicting_contexts_2.append('NA')\n",
    "        train_conflicting_answers_2.append('NA')\n",
    "        train_cited_conflicting_answers_1.append('NA')\n",
    "        train_cited_conflicting_answers_2.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val\n",
    "val_conflicting_contexts_1 = []\n",
    "val_conflicting_answers_1 = []\n",
    "val_conflicting_contexts_2 = []\n",
    "val_conflicting_answers_2 = []\n",
    "val_cited_conflicting_answers_1 = []\n",
    "val_cited_conflicting_answers_2 = []\n",
    "\n",
    "for entry_idx in range(len(val_original_contexts)):\n",
    "    if entry_idx % 100 == 0:\n",
    "        print(f'entry_idx: {entry_idx} out of {len(val_original_contexts)}')\n",
    "    try:\n",
    "        original_answer = val_original_answers[entry_idx]\n",
    "        original_context = val_cited_oracle_contexts[entry_idx]\n",
    "        if original_answer in original_context:\n",
    "            question = val_questions[entry_idx]\n",
    "            # mask\n",
    "            masked_context = original_context.replace(original_answer, '<mask>', 1) # only replace the first occurence because the fill-mask pipeline can only handle 1 mask at a time (it can do more but then the results look different)\n",
    "            # predict\n",
    "            fill_mask_result = classifier(masked_context) # Note that token_str may contain spaces\n",
    "            # extract\n",
    "            fill_mask_sequences = [i['sequence'] for i in fill_mask_result]\n",
    "            fill_mask_answers = [i['token_str'].strip() for i in fill_mask_result] # remove extra spaces from the pipelines potential result\n",
    "            try:\n",
    "                fill_mask_answers.remove(original_answer) # filter -- remove answers if its the original and append the remaining context and answers\n",
    "            except ValueError: pass # not in list\n",
    "            for idx in range(2): # only append the first 2 answers for 2 conflicting contexts\n",
    "                if idx == 0:\n",
    "                    val_conflicting_contexts_1.append(original_context.replace(original_answer, fill_mask_answers[idx]).replace('  ', ' ')) # and remove extra spaces from the pipeline's potential result)\n",
    "                    val_conflicting_answers_1.append(fill_mask_answers[idx])\n",
    "                    val_cited_conflicting_answers_1.append(val_cited_original_answers[entry_idx].replace(original_answer, fill_mask_answers[idx]).replace('  ', ' '))\n",
    "                if idx == 1:\n",
    "                    val_conflicting_contexts_2.append(original_context.replace(original_answer, fill_mask_answers[idx]).replace('  ', ' ')) # and remove extra spaces from the pipeline's potential result)\n",
    "                    val_conflicting_answers_2.append(fill_mask_answers[idx])\n",
    "                    val_cited_conflicting_answers_2.append(val_cited_original_answers[entry_idx].replace(original_answer, fill_mask_answers[idx]).replace('  ', ' '))\n",
    "\n",
    "            # break\n",
    "        else: # answer does not appear in the context (still need to append something)\n",
    "            val_conflicting_contexts_1.append('NA')\n",
    "            val_conflicting_answers_1.append('NA')\n",
    "            val_conflicting_contexts_2.append('NA')\n",
    "            val_conflicting_answers_2.append('NA')\n",
    "            val_cited_conflicting_answers_1.append('NA')\n",
    "            val_cited_conflicting_answers_2.append('NA')\n",
    "    except (RuntimeError, IndexError) as e: # context is too long\n",
    "        val_conflicting_contexts_1.append('NA')\n",
    "        val_conflicting_answers_1.append('NA')\n",
    "        val_conflicting_contexts_2.append('NA')\n",
    "        val_conflicting_answers_2.append('NA')\n",
    "        val_cited_conflicting_answers_1.append('NA')\n",
    "        val_cited_conflicting_answers_2.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add distractors to the conflicting context\n",
    "\n",
    "# # train\n",
    "train_full_conflicting_contexts_1 = [f'{conflicting_context_1} {distractor_context}' for conflicting_context_1, distractor_context in zip(train_conflicting_contexts_1,train_distractor_contexts)]\n",
    "train_full_conflicting_contexts_2 = [f'{conflicting_context_2} {distractor_context}' for conflicting_context_2, distractor_context in zip(train_conflicting_contexts_2,train_distractor_contexts)]\n",
    "\n",
    "# val\n",
    "val_full_conflicting_contexts_1 = [f'{conflicting_context_1} {distractor_context}' for conflicting_context_1, distractor_context in zip(val_conflicting_contexts_1,val_distractor_contexts)]\n",
    "val_full_conflicting_contexts_2 = [f'{conflicting_context_2} {distractor_context}' for conflicting_context_2, distractor_context in zip(val_conflicting_contexts_2,val_distractor_contexts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame({\n",
    "    'questions' : train_questions,\n",
    "    'original_contexts' : train_original_contexts,\n",
    "    'original_answers' : train_original_answers,\n",
    "    'conflicting_contexts_1' : train_conflicting_contexts_1,\n",
    "    'conflicting_answers_1' : train_conflicting_answers_1,\n",
    "    'conflicting_contexts_2' : train_conflicting_contexts_2,\n",
    "    'conflicting_answers_2' : train_conflicting_answers_2,\n",
    "    'cited_original_answers' : train_cited_original_answers,\n",
    "    'cited_conflicting_answers_1' : train_cited_conflicting_answers_1,\n",
    "    'cited_conflicting_answers_2' : train_cited_conflicting_answers_2,\n",
    "    'title_to_contexts' : train_title_to_contexts,\n",
    "    'cited_oracle_contexts' : train_cited_oracle_contexts,\n",
    "    'distractor_contexts': train_distractor_contexts,\n",
    "    'number_of_documents_list' : train_number_of_documents_list,\n",
    "    'full_conflicting_contexts_1': train_full_conflicting_contexts_1,\n",
    "    'full_conflicting_contexts_2': train_full_conflicting_contexts_2,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.DataFrame({\n",
    "    'questions' : val_questions,\n",
    "    'original_contexts' : val_original_contexts,\n",
    "    'original_answers' : val_original_answers,\n",
    "    'conflicting_contexts_1' : val_conflicting_contexts_1,\n",
    "    'conflicting_answers_1' : val_conflicting_answers_1,\n",
    "    'conflicting_contexts_2' : val_conflicting_contexts_2,\n",
    "    'conflicting_answers_2' : val_conflicting_answers_2,\n",
    "    'cited_original_answers' : val_cited_original_answers,\n",
    "    'cited_conflicting_answers_1' : val_cited_conflicting_answers_1,\n",
    "    'cited_conflicting_answers_2' : val_cited_conflicting_answers_2,\n",
    "    'title_to_contexts' : val_title_to_contexts,\n",
    "    'cited_oracle_contexts' : val_cited_oracle_contexts,\n",
    "    'distractor_contexts': val_distractor_contexts,\n",
    "    'number_of_documents_list' : val_number_of_documents_list,\n",
    "    'full_conflicting_contexts_1': val_full_conflicting_contexts_1,\n",
    "    'full_conflicting_contexts_2': val_full_conflicting_contexts_2,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_df = train_df.drop(train_df[train_df.conflicting_contexts_1 == 'NA'].index).reset_index(drop=True)\n",
    "clean_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_val_df = val_df.drop(val_df[val_df.conflicting_contexts_1 == 'NA'].index).reset_index(drop=True)\n",
    "clean_val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dictionaries\n",
    "train_dict = clean_train_df.to_dict('list') \n",
    "# save final dataset to json\n",
    "with open('datasets/hotpotqa_train.json', 'w') as fp:\n",
    "    json.dump(train_dict, fp)\n",
    "\n",
    "# # split val into val and test\n",
    "val_merged_df_1 = clean_val_df[:len(clean_val_df)//2]\n",
    "val_merged_df_2 = clean_val_df[len(clean_val_df)//2:]\n",
    "\n",
    "val_dict = val_merged_df_1.to_dict('list')\n",
    "test_dict = val_merged_df_2.to_dict('list')\n",
    "\n",
    "with open('datasets/hotpotqa_val.json', 'w') as fp:\n",
    "    json.dump(val_dict, fp)\n",
    "\n",
    "with open('datasets/hotpotqa_test.json', 'w') as fp:\n",
    "    json.dump(test_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "with open('datasets/hotpotqa_train.json', 'r') as fp:\n",
    "    hotpotqa_train = json.load(fp)\n",
    "with open('datasets/hotpotqa_val.json', 'r') as fp:\n",
    "    hotpotqa_val = json.load(fp)\n",
    "with open('datasets/hotpotqa_test.json', 'r') as fp:\n",
    "    hotpotqa_test = json.load(fp)\n",
    "\n",
    "# # print(len(hotpotqa_train['questions']))\n",
    "# print(len(hotpotqa_val['questions']))\n",
    "# print(len(hotpotqa_test['questions']))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# organize the final dataset by combining all the conflicting contexts and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train_new_cited_conflicting_answers_1 = []\n",
    "train_new_conflicting_contexts_1 = []\n",
    "train_new_cited_conflicting_answers_2 = []\n",
    "train_new_conflicting_contexts_2 = []\n",
    "\n",
    "for entry_idx in range(len(hotpotqa_train['number_of_documents_list'])):\n",
    "    # entry_idx = 0\n",
    "    number_of_documents = hotpotqa_train['number_of_documents_list'][entry_idx]\n",
    "    counter = 1 # by how much to increase the document citation count\n",
    "\n",
    "    tmp_cited_conflicting_answer_1 = hotpotqa_train['cited_conflicting_answers_1'][entry_idx]\n",
    "    tmp_conflicting_context_1 = hotpotqa_train['conflicting_contexts_1'][entry_idx]\n",
    "    for possible_doc_string in hotpotqa_train['cited_conflicting_answers_1'][entry_idx].split(\"'\"):\n",
    "        if 'Document ' in possible_doc_string:\n",
    "            doc_int = possible_doc_string.split(' ')\n",
    "            new_doc_int = counter + number_of_documents\n",
    "            new_citation_string = f'Document {new_doc_int}'\n",
    "            tmp_cited_conflicting_answer_1 = tmp_cited_conflicting_answer_1.replace(possible_doc_string, new_citation_string)\n",
    "            tmp_conflicting_context_1 = tmp_conflicting_context_1.replace(possible_doc_string, new_citation_string)\n",
    "            counter += 1 # increase citation counter\n",
    "\n",
    "    train_new_cited_conflicting_answers_1.append(tmp_cited_conflicting_answer_1)\n",
    "    train_new_conflicting_contexts_1.append(tmp_conflicting_context_1)\n",
    "\n",
    "\n",
    "    tmp_cited_conflicting_answer_2 = hotpotqa_train['cited_conflicting_answers_2'][entry_idx]\n",
    "    tmp_conflicting_context_2 = hotpotqa_train['conflicting_contexts_2'][entry_idx]\n",
    "    for possible_doc_string in hotpotqa_train['cited_conflicting_answers_2'][entry_idx].split(\"'\"):\n",
    "        if 'Document ' in possible_doc_string:\n",
    "            doc_int = possible_doc_string.split(' ')\n",
    "            new_doc_int = counter + number_of_documents\n",
    "            new_citation_string = f'Document {new_doc_int}'\n",
    "            tmp_cited_conflicting_answer_2 = tmp_cited_conflicting_answer_2.replace(possible_doc_string, new_citation_string)\n",
    "            tmp_conflicting_context_2 = tmp_conflicting_context_2.replace(possible_doc_string, new_citation_string)\n",
    "            counter += 1 # increase citation counter\n",
    "\n",
    "    train_new_cited_conflicting_answers_2.append(tmp_cited_conflicting_answer_2)\n",
    "    train_new_conflicting_contexts_2.append(tmp_conflicting_context_2)\n",
    "\n",
    "train_cited_context = [f'{hotpotqa_train[\"original_contexts\"][entry_idx]} {train_new_conflicting_contexts_1[entry_idx]} {train_new_conflicting_contexts_2[entry_idx]}' for entry_idx in range(len(hotpotqa_train['original_contexts']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val\n",
    "val_new_cited_conflicting_answers_1 = []\n",
    "val_new_conflicting_contexts_1 = []\n",
    "val_new_cited_conflicting_answers_2 = []\n",
    "val_new_conflicting_contexts_2 = []\n",
    "\n",
    "for entry_idx in range(len(hotpotqa_val['number_of_documents_list'])):\n",
    "    # entry_idx = 0\n",
    "    number_of_documents = hotpotqa_val['number_of_documents_list'][entry_idx]\n",
    "    counter = 1 # by how much to increase the document citation count\n",
    "\n",
    "    tmp_cited_conflicting_answer_1 = hotpotqa_val['cited_conflicting_answers_1'][entry_idx]\n",
    "    tmp_conflicting_context_1 = hotpotqa_val['conflicting_contexts_1'][entry_idx]\n",
    "    for possible_doc_string in hotpotqa_val['cited_conflicting_answers_1'][entry_idx].split(\"'\"):\n",
    "        if 'Document ' in possible_doc_string:\n",
    "            doc_int = possible_doc_string.split(' ')\n",
    "            new_doc_int = counter + number_of_documents\n",
    "            new_citation_string = f'Document {new_doc_int}'\n",
    "            tmp_cited_conflicting_answer_1 = tmp_cited_conflicting_answer_1.replace(possible_doc_string, new_citation_string)\n",
    "            tmp_conflicting_context_1 = tmp_conflicting_context_1.replace(possible_doc_string, new_citation_string)\n",
    "            counter += 1 # increase citation counter\n",
    "\n",
    "    val_new_cited_conflicting_answers_1.append(tmp_cited_conflicting_answer_1)\n",
    "    val_new_conflicting_contexts_1.append(tmp_conflicting_context_1)\n",
    "\n",
    "\n",
    "    tmp_cited_conflicting_answer_2 = hotpotqa_val['cited_conflicting_answers_2'][entry_idx]\n",
    "    tmp_conflicting_context_2 = hotpotqa_val['conflicting_contexts_2'][entry_idx]\n",
    "    for possible_doc_string in hotpotqa_val['cited_conflicting_answers_2'][entry_idx].split(\"'\"):\n",
    "        if 'Document ' in possible_doc_string:\n",
    "            doc_int = possible_doc_string.split(' ')\n",
    "            new_doc_int = counter + number_of_documents\n",
    "            new_citation_string = f'Document {new_doc_int}'\n",
    "            tmp_cited_conflicting_answer_2 = tmp_cited_conflicting_answer_2.replace(possible_doc_string, new_citation_string)\n",
    "            tmp_conflicting_context_2 = tmp_conflicting_context_2.replace(possible_doc_string, new_citation_string)\n",
    "            counter += 1 # increase citation counter\n",
    "\n",
    "    val_new_cited_conflicting_answers_2.append(tmp_cited_conflicting_answer_2)\n",
    "    val_new_conflicting_contexts_2.append(tmp_conflicting_context_2)\n",
    "\n",
    "val_cited_context = [f'{hotpotqa_val[\"original_contexts\"][entry_idx]} {val_new_conflicting_contexts_1[entry_idx]} {val_new_conflicting_contexts_2[entry_idx]}' for entry_idx in range(len(hotpotqa_val['original_contexts']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_new_cited_conflicting_answers_1 = []\n",
    "test_new_conflicting_contexts_1 = []\n",
    "test_new_cited_conflicting_answers_2 = []\n",
    "test_new_conflicting_contexts_2 = []\n",
    "\n",
    "for entry_idx in range(len(hotpotqa_test['number_of_documents_list'])):\n",
    "    # entry_idx = 0\n",
    "    number_of_documents = hotpotqa_test['number_of_documents_list'][entry_idx]\n",
    "    counter = 1 # by how much to increase the document citation count\n",
    "\n",
    "    tmp_cited_conflicting_answer_1 = hotpotqa_test['cited_conflicting_answers_1'][entry_idx]\n",
    "    tmp_conflicting_context_1 = hotpotqa_test['conflicting_contexts_1'][entry_idx]\n",
    "    for possible_doc_string in hotpotqa_test['cited_conflicting_answers_1'][entry_idx].split(\"'\"):\n",
    "        if 'Document ' in possible_doc_string:\n",
    "            doc_int = possible_doc_string.split(' ')\n",
    "            new_doc_int = counter + number_of_documents\n",
    "            new_citation_string = f'Document {new_doc_int}'\n",
    "            tmp_cited_conflicting_answer_1 = tmp_cited_conflicting_answer_1.replace(possible_doc_string, new_citation_string)\n",
    "            tmp_conflicting_context_1 = tmp_conflicting_context_1.replace(possible_doc_string, new_citation_string)\n",
    "            counter += 1 # increase citation counter\n",
    "\n",
    "    test_new_cited_conflicting_answers_1.append(tmp_cited_conflicting_answer_1)\n",
    "    test_new_conflicting_contexts_1.append(tmp_conflicting_context_1)\n",
    "\n",
    "\n",
    "    tmp_cited_conflicting_answer_2 = hotpotqa_test['cited_conflicting_answers_2'][entry_idx]\n",
    "    tmp_conflicting_context_2 = hotpotqa_test['conflicting_contexts_2'][entry_idx]\n",
    "    for possible_doc_string in hotpotqa_test['cited_conflicting_answers_2'][entry_idx].split(\"'\"):\n",
    "        if 'Document ' in possible_doc_string:\n",
    "            doc_int = possible_doc_string.split(' ')\n",
    "            new_doc_int = counter + number_of_documents\n",
    "            new_citation_string = f'Document {new_doc_int}'\n",
    "            tmp_cited_conflicting_answer_2 = tmp_cited_conflicting_answer_2.replace(possible_doc_string, new_citation_string)\n",
    "            tmp_conflicting_context_2 = tmp_conflicting_context_2.replace(possible_doc_string, new_citation_string)\n",
    "            counter += 1 # increase citation counter\n",
    "\n",
    "    test_new_cited_conflicting_answers_2.append(tmp_cited_conflicting_answer_2)\n",
    "    test_new_conflicting_contexts_2.append(tmp_conflicting_context_2)\n",
    "\n",
    "test_cited_context = [f'{hotpotqa_test[\"original_contexts\"][entry_idx]} {test_new_conflicting_contexts_1[entry_idx]} {test_new_conflicting_contexts_2[entry_idx]}' for entry_idx in range(len(hotpotqa_test['original_contexts']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train_df = pd.DataFrame({\n",
    "    'question' : hotpotqa_train['questions'],\n",
    "    'original_context' : hotpotqa_train['original_contexts'],\n",
    "    'original_answer' : hotpotqa_train['original_answers'],\n",
    "    'conflicting_contexts_1' : hotpotqa_train['conflicting_contexts_1'],\n",
    "    'conflicting_answers_1' : hotpotqa_train['conflicting_answers_1'],\n",
    "    'conflicting_contexts_2' : hotpotqa_train['conflicting_contexts_2'],\n",
    "    'conflicting_answers_2' : hotpotqa_train['conflicting_answers_2'],\n",
    "    'cited_original_answers' : hotpotqa_train['cited_original_answers'],\n",
    "    'cited_conflicting_answers_1' : hotpotqa_train['cited_conflicting_answers_1'],\n",
    "    'cited_conflicting_answers_2' : hotpotqa_train['cited_conflicting_answers_2'],\n",
    "    'title_to_contexts' : hotpotqa_train['title_to_contexts'],\n",
    "    'cited_oracle_contexts' : hotpotqa_train['cited_oracle_contexts'],\n",
    "    'distractor_contexts': hotpotqa_train['distractor_contexts'],\n",
    "    'number_of_documents_list' : hotpotqa_train['number_of_documents_list'],\n",
    "    'full_conflicting_contexts_1': hotpotqa_train['full_conflicting_contexts_1'],\n",
    "    'full_conflicting_contexts_2': hotpotqa_train['full_conflicting_contexts_2'],\n",
    "    'cited_context' : train_cited_context,\n",
    "    'new_conflicting_contexts_1': train_new_conflicting_contexts_1,\n",
    "    'new_conflicting_contexts_2': train_new_conflicting_contexts_2,\n",
    "    'new_cited_conflicting_answers_1': train_new_cited_conflicting_answers_1,\n",
    "    'new_cited_conflicting_answers_2': train_new_cited_conflicting_answers_2,\n",
    "    })\n",
    "\n",
    "# # val\n",
    "val_df = pd.DataFrame({\n",
    "    'question' : hotpotqa_val['questions'],\n",
    "    'original_context' : hotpotqa_val['original_contexts'],\n",
    "    'original_answer' : hotpotqa_val['original_answers'],\n",
    "    'conflicting_contexts_1' : hotpotqa_val['conflicting_contexts_1'],\n",
    "    'conflicting_answers_1' : hotpotqa_val['conflicting_answers_1'],\n",
    "    'conflicting_contexts_2' : hotpotqa_val['conflicting_contexts_2'],\n",
    "    'conflicting_answers_2' : hotpotqa_val['conflicting_answers_2'],\n",
    "    'cited_original_answers' : hotpotqa_val['cited_original_answers'],\n",
    "    'cited_conflicting_answers_1' : hotpotqa_val['cited_conflicting_answers_1'],\n",
    "    'cited_conflicting_answers_2' : hotpotqa_val['cited_conflicting_answers_2'],\n",
    "    'title_to_contexts' : hotpotqa_val['title_to_contexts'],\n",
    "    'cited_oracle_contexts' : hotpotqa_val['cited_oracle_contexts'],\n",
    "    'distractor_contexts': hotpotqa_val['distractor_contexts'],\n",
    "    'number_of_documents_list' : hotpotqa_val['number_of_documents_list'],\n",
    "    'full_conflicting_contexts_1': hotpotqa_val['full_conflicting_contexts_1'],\n",
    "    'full_conflicting_contexts_2': hotpotqa_val['full_conflicting_contexts_2'],\n",
    "    'cited_context' : val_cited_context,\n",
    "    'new_conflicting_contexts_1': val_new_conflicting_contexts_1,\n",
    "    'new_conflicting_contexts_2': val_new_conflicting_contexts_2,\n",
    "    'new_cited_conflicting_answers_1': val_new_cited_conflicting_answers_1,\n",
    "    'new_cited_conflicting_answers_2': val_new_cited_conflicting_answers_2,\n",
    "    })\n",
    "\n",
    "# # test\n",
    "test_df = pd.DataFrame({\n",
    "    'question' : hotpotqa_test['questions'],\n",
    "    'original_context' : hotpotqa_test['original_contexts'],\n",
    "    'original_answer' : hotpotqa_test['original_answers'],\n",
    "    'conflicting_contexts_1' : hotpotqa_test['conflicting_contexts_1'],\n",
    "    'conflicting_answers_1' : hotpotqa_test['conflicting_answers_1'],\n",
    "    'conflicting_contexts_2' : hotpotqa_test['conflicting_contexts_2'],\n",
    "    'conflicting_answers_2' : hotpotqa_test['conflicting_answers_2'],\n",
    "    'cited_original_answers' : hotpotqa_test['cited_original_answers'],\n",
    "    'cited_conflicting_answers_1' : hotpotqa_test['cited_conflicting_answers_1'],\n",
    "    'cited_conflicting_answers_2' : hotpotqa_test['cited_conflicting_answers_2'],\n",
    "    'title_to_contexts' : hotpotqa_test['title_to_contexts'],\n",
    "    'cited_oracle_contexts' : hotpotqa_test['cited_oracle_contexts'],\n",
    "    'distractor_contexts': hotpotqa_test['distractor_contexts'],\n",
    "    'number_of_documents_list' : hotpotqa_test['number_of_documents_list'],\n",
    "    'full_conflicting_contexts_1': hotpotqa_test['full_conflicting_contexts_1'],\n",
    "    'full_conflicting_contexts_2': hotpotqa_test['full_conflicting_contexts_2'],\n",
    "    'cited_context' : test_cited_context,\n",
    "    'new_conflicting_contexts_1': test_new_conflicting_contexts_1,\n",
    "    'new_conflicting_contexts_2': test_new_conflicting_contexts_2,\n",
    "    'new_cited_conflicting_answers_1': test_new_cited_conflicting_answers_1,\n",
    "    'new_cited_conflicting_answers_2': test_new_cited_conflicting_answers_2,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_df))\n",
    "# print(len(val_df))\n",
    "# print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['cited_context'][1].split('Document ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df['new_cited_conflicting_answers_1'][1])\n",
    "print(test_df['new_cited_conflicting_answers_2'][1])\n",
    "print(test_df['cited_original_answers'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save final datasets\n",
    "# convert to dictionaries\n",
    "train_dict = train_df.to_dict('list')\n",
    "val_dict = val_df.to_dict('list')\n",
    "test_dict = test_df.to_dict('list')\n",
    "\n",
    "# save final dataset to json\n",
    "with open('datasets/hotpotqa_train_final.json', 'w') as fp:\n",
    "    json.dump(train_dict, fp)\n",
    "\n",
    "with open('datasets/hotpotqa_val_final.json', 'w') as fp:\n",
    "    json.dump(val_dict, fp)\n",
    "with open('datasets/hotpotqa_test_final.json', 'w') as fp:\n",
    "    json.dump(test_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "with open('datasets/hotpotqa_train_final.json', 'r') as fp:\n",
    "    hotpotqa_train = json.load(fp)\n",
    "with open('datasets/hotpotqa_val_final.json', 'r') as fp:\n",
    "    hotpotqa_val = json.load(fp)\n",
    "with open('datasets/hotpotqa_test_final.json', 'r') as fp:\n",
    "    hotpotqa_test = json.load(fp)\n",
    "\n",
    "# print(len(hotpotqa_train['question']))\n",
    "print(len(hotpotqa_val['question']))\n",
    "print(len(hotpotqa_test['question']))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(hotpotqa_train).head()\n",
    "for k in hotpotqa_train.keys():\n",
    "    print(k)\n",
    "    print(hotpotqa_train[k][2])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "01f989aa223c0c84311f46d7580eb8fa94f35fe0e1d6e5c1d38b7062bc3d2b8b"
  },
  "kernelspec": {
   "display_name": "Python 3.12.3 ('oracle')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
